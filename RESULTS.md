# ğŸ“Š ATF Benchmark Results

Comprehensive benchmark results comparing ATF against baseline training across vision and NLP tasks.

---

## ğŸ“‹ Test Configuration

| Parameter | Value |
|-----------|-------|
| **Hardware** | NVIDIA RTX GPU, CUDA 12+ |
| **PyTorch** | 2.0+ |
| **Seed** | 42 (all experiments) |
| **Optimizer** | AdamW |
| **ATF Modules** | CA, GF, PLR, CD, TB, HI, MC (unless noted) |

---

## ğŸ–¼ï¸ Vision Tasks

### MNIST (20 epochs)

| Metric | Baseline | ATF | Î” |
|--------|----------|-----|---|
| **Best Accuracy** | 99.44% | 99.33% | -0.11% |
| **Best Epoch** | 20 | 13 | -7 |
| **Training Time** | 3m 51s | 3m 53s | â‰ˆ |
| **Early Stopped** | No | Yes (epoch 17) | âœ“ |

```
Accuracy over Epochs:
100% â”¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Baseline
     â”‚                                              â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ATF (stopped)
 99% â”¤ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
     â”‚
 98% â”¤
     â”‚
 97% â”¤
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       1    3    5    7    9   11   13   15   17   19   20
                            Epoch

Verdict: TIE - MNIST is a "solved" problem (~99.5% ceiling)
         ATF correctly detected plateau and stopped early
```

---

### CIFAR-10 (50 epochs)

| Metric | Baseline | ATF | Î” |
|--------|----------|-----|---|
| **Best Accuracy** | 90.54% | 90.45% | -0.09% |
| **Best Epoch** | 43 | 26 | -17 |
| **Training Time** | 14m 11s | 9m 8s | **-36%** |
| **Early Stopped** | No | Yes | âœ“ |

```
Accuracy over Epochs:
 92% â”¤
     â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Baseline (90.54%)
 90% â”¤               â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
     â”‚         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
 88% â”¤    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     ATF stopped @ 26 (90.45%)
     â”‚  â–ˆâ–ˆ
 86% â”¤â–ˆâ–ˆ
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       1    5    10   15   20   25   30   35   40   45   50
                            Epoch

Training Time Comparison:
Baseline: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 14m 11s
ATF:      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   9m 8s (-36%)

Verdict: ATF WINS â±ï¸ - Same accuracy, 36% faster
```

---

### CIFAR-100 (75 epochs)

| Metric | Baseline | ATF | Î” |
|--------|----------|-----|---|
| **Best Accuracy** | 68.58% | **69.33%** | **+0.75%** ğŸ† |
| **Best Epoch** | 67 | 31 | -36 |
| **Training Time** | 30m 27s | 12m 36s | **-59%** |
| **Early Stopped** | No | Yes | âœ“ |

```
Accuracy over Epochs:
 70% â”¤                                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Baseline (68.58%)
     â”‚                              â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
 68% â”¤               â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ATF (69.33%) ğŸ†
     â”‚         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
 66% â”¤    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      ATF stopped @ 31
     â”‚  â–ˆâ–ˆ
 64% â”¤â–ˆâ–ˆ
     â”‚
 62% â”¤
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       1    10   20   30   40   50   60   70   75
                            Epoch

Training Time Comparison:
Baseline: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 30m 27s
ATF:      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                     12m 36s (-59%)

Verdict: ATF WINS ğŸ† - Better accuracy (+0.75%) AND 59% faster!
```

---

### Fashion-MNIST (20 epochs)

| Metric | Baseline | ATF | Î” |
|--------|----------|-----|---|
| **Best Accuracy** | 92.59% | 92.80% | +0.21% |
| **Training Time** | ~4m | ~3m | -23% |
| **Early Stopped** | No | Yes | âœ“ |

```
Verdict: ATF WINS - Slightly better accuracy, faster training
```

---

## ğŸ“ NLP Tasks (BERT Fine-tuning)

### SST-2 - Sentiment Analysis (5 epochs)

| Metric | Baseline | ATF | Î” |
|--------|----------|-----|---|
| **Best Accuracy** | **93.00%** | 92.43% | -0.57% |
| **Best Epoch** | 5 | 2 | -3 |
| **Training Time** | 29m 29s | 24m 6s | -18% |
| **Early Stopped** | No | Yes (epoch 2) | âš ï¸ |

```
Accuracy over Epochs:
 94% â”¤
     â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Baseline (93.00%) ğŸ†
 93% â”¤                   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
     â”‚              â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
 92% â”¤    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      ATF (92.43%)
     â”‚  â–ˆâ–ˆ           ATF stopped early!
 91% â”¤â–ˆâ–ˆ
     â”‚
 90% â”¤
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       1         2         3         4         5
                       Epoch

Analysis:
- SST-2 has 67k training samples (large dataset)
- BERT is already pre-trained and well-optimized
- ATF oscillations can destabilize fine-tuning
- Early stopping triggered too soon (patience=2)

Verdict: BASELINE WINS - Use baseline for large NLP datasets
```

---

### MRPC - Paraphrase Detection (5 epochs)

| Metric | Baseline | ATF | Î” |
|--------|----------|-----|---|
| **Best Accuracy** | 84.80% | **87.25%** | **+2.45%** ğŸ† |
| **Best Epoch** | 2 | 3 | +1 |
| **Training Time** | 5m 49s | 4m 54s | -16% |
| **Early Stopped** | No | No | - |

```
Accuracy over Epochs:
 88% â”¤                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ATF (87.25%) ğŸ†
     â”‚              â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
 86% â”¤         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
     â”‚    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Baseline (84.80%)
 84% â”¤â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
     â”‚
 82% â”¤
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       1         2         3         4         5
                       Epoch

Analysis:
- MRPC has only 3.7k training samples (small dataset)
- High risk of overfitting
- ATF oscillations act as regularization
- Convergence damper prevents overfitting

Verdict: ATF WINS ğŸ† - +2.45% accuracy on small dataset!
```

---

## ğŸ“ˆ Summary Charts

### Overall Results

```
                        Accuracy Comparison
                 
CIFAR-100    â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“ 69.33% ATF ğŸ†
             â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 68.58% Base

CIFAR-10     â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“ 90.45% ATF
             â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 90.54% Base

MNIST        â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“ 99.33% ATF
             â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 99.44% Base

BERT MRPC    â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“ 87.25% ATF ğŸ†
             â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 84.80% Base

BERT SST-2   â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“ 92.78% ATF
             â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 93.23% Base ğŸ†

             0%       25%       50%       75%      100%
```

### Time Savings

```
                        Training Time Reduction

CIFAR-100    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ -59% âš¡âš¡âš¡
CIFAR-10     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ -36% âš¡âš¡
F-MNIST      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ -23% âš¡
BERT SST-2   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ -18%
BERT MRPC    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ -16%
MNIST        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â‰ˆ0%

             0%                                               100%
             â—€â”€â”€â”€â”€ Time Saved â”€â”€â”€â”€â–¶                    Full Time
```

---

## ğŸ† Win/Loss Summary

| Dataset | Size | Complexity | Winner | Why |
|---------|------|------------|--------|-----|
| CIFAR-100 | 50k | High (100 classes) | **ATF** ğŸ† | +0.75% acc, -59% time |
| CIFAR-10 | 50k | Medium | **ATF** â±ï¸ | Same acc, -36% time |
| MNIST | 60k | Low | Tie | Solved problem |
| Fashion-MNIST | 60k | Low-Med | **ATF** | +0.21%, -23% time |
| BERT MRPC | 3.7k | High (small data) | **ATF** ğŸ† | +2.45% acc |
| BERT SST-2 | 67k | Low (large data) | Baseline | ATF early-stopped too soon |

### Score

```
ATF Wins:      4  (CIFAR-100, CIFAR-10, Fashion-MNIST, MRPC)
Baseline Wins: 1  (SST-2)
Ties:          1  (MNIST)

ATF Success Rate: 67%
```

---

## ğŸ’¡ Key Insights

### When to Use ATF

âœ… **Use ATF for:**
- Complex tasks with many classes (CIFAR-100)
- Small datasets prone to overfitting (MRPC)
- Training from scratch (not fine-tuning)
- When you need faster training with early stopping

âŒ **Use Baseline for:**
- Pre-trained models on large datasets (BERT on SST-2)
- Already well-optimized training setups
- Very simple tasks (MNIST-level)

### ATF Module Recommendations

| Scenario | Recommended Modules |
|----------|---------------------|
| Vision (general) | CA + PLR + MC + CD + GF + TB + HI |
| BERT (small data) | CA + MC + CD + PLR (no HI, GF, TB) |
| BERT (large data) | Baseline (no ATF) |
| Aggressive | All + high Ï‰ (7.0) and amp (0.12) |
| Conservative | CA + MC + PLR + CD with low amp (0.04) |

---

## ğŸ”¬ Training Collapse Prevention

One of ATF's key strengths is preventing catastrophic training collapse.

### Example: CIFAR-10 Collapse Scenario

Under certain conditions (bad initialization, aggressive LR), baseline training can collapse:

```
Without ATF (collapsed run):
Epoch  1: 45.2%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Epoch  5: 52.3%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Epoch 10: 48.1%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Epoch 15: 43.2%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Epoch 20: 40.7%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          â† Collapsed to near-random!

With ATF (same conditions):
Epoch  1: 44.8%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Epoch  5: 61.2%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Epoch 10: 72.4%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Epoch 15: 77.8%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Epoch 20: 80.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  âœ“ Stable!

Difference: 40.65% â†’ 80.03% = +39.38 percentage points!
```

ATF's convergence damper and meta controller detect divergence early and correct course.

---

## ğŸ“– Reproducing Results

All experiments can be reproduced using the GUI or CLI:

```bash
# CIFAR-100 Baseline
python -m atf.cli.run --dataset cifar100 --epochs 75 --baseline

# CIFAR-100 ATF
python -m atf.cli.run --dataset cifar100 --epochs 75 --atf --omega 6.0 --amp 0.08 --patience 5

# BERT MRPC ATF
python -m atf.cli.run --dataset bert_mrpc --epochs 5 --atf --patience 3 --amp 0.01 --hi off --gfc off
```

Or use the GUI presets for one-click reproduction.

---

<p align="center">
  <strong>Results by Damjan Å½akelj</strong><br>
  <em>All experiments conducted with seed=42 for reproducibility</em>
</p>
